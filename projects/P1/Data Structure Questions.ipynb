{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Structure used in problems "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkedListNode:\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.next = None\n",
    "\n",
    "class Stack:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.num_elements = 0\n",
    "        self.head = None\n",
    "\n",
    "    def push(self, data):\n",
    "        new_node = LinkedListNode(data)\n",
    "        if self.head is None:\n",
    "            self.head = new_node\n",
    "        else:\n",
    "            new_node.next = self.head\n",
    "            self.head = new_node\n",
    "        self.num_elements += 1\n",
    "\n",
    "    def pop(self):\n",
    "        if self.is_empty():\n",
    "            return None\n",
    "        temp = self.head.data\n",
    "        self.head = self.head.next\n",
    "        self.num_elements -= 1\n",
    "        return temp\n",
    "\n",
    "    def top(self):\n",
    "        if self.head is None:\n",
    "            return None\n",
    "        return self.head.data\n",
    "\n",
    "    def size(self):\n",
    "        return self.num_elements\n",
    "\n",
    "    def is_empty(self):\n",
    "        return self.num_elements == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: LRU Cache\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Recently Used Cache\n",
    "\n",
    "We have briefly discussed caching as part of a practice problem while studying hash maps.\n",
    "\n",
    "The lookup operation (i.e., get()) and put() / set() is supposed to be fast for a cache memory.\n",
    "\n",
    "While doing the get() operation, if the entry is found in the cache, it is known as a cache hit. If, however, the entry is not found, it is known as a cache miss.\n",
    "\n",
    "When designing a cache, we also place an upper bound on the size of the cache. If the cache is full and we want to add a new entry to the cache, we use some criteria to remove an element. After removing an element, we use the put() operation to insert the new element. The remove operation should also be fast.\n",
    "\n",
    "For our first problem, the goal will be to design a data structure known as a Least Recently Used (LRU) cache. An LRU cache is a type of cache in which we remove the least recently used entry when the cache memory reaches its limit. For the current problem, consider both get and set operations as an use operation.\n",
    "\n",
    "Your job is to use an appropriate data structure(s) to implement the cache.\n",
    "\n",
    "In case of a cache hit, your get() operation should return the appropriate value.\n",
    "- In case of a cache miss, your get() should return -1.\n",
    "- While putting an element in the cache, your put() / set() operation must insert the element. If the cache is full, you must write code that removes the least recently used entry first and then insert the element.\n",
    "- All operations must take O(1) time.\n",
    "\n",
    "For the current problem, you can consider the size of cache = 5.\n",
    "\n",
    "Here is some boiler plate code and some example test cases to get you started on this problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "-1\n",
      "-1\n",
      "Warning: LRU capacity is 0\n",
      "Warning: LRU capacity is 0\n",
      "-1\n",
      "10\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "class LRU_Node:\n",
    "    def __init__(self, key, value):\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "        self.prev = None\n",
    "        self.next = None\n",
    "            \n",
    "\n",
    "class LRU_Cache:\n",
    "    def __init__(self, capacity = 5):\n",
    "        ''' #Initialize LRU_Cache node  '''\n",
    "        \n",
    "        self.hmap = dict()\n",
    "        self.capacity = capacity\n",
    "        self.num_entries = 0\n",
    "        self.head = None\n",
    "        self.tail = None\n",
    "    \n",
    "        \n",
    "    # get(key)    \n",
    "    def get(self, key):\n",
    "        \n",
    "        if self.capacity == 0:\n",
    "            print(\"Warning: LRU capacity is 0\")\n",
    "\n",
    "        # Check for key in hash map\n",
    "        if self.hmap.get(key) is not None:\n",
    "            node = self.hmap[key]\n",
    "            \n",
    "            # Update tail pointer if item removed is tail node\n",
    "            if node == self.tail:\n",
    "                self.tail = node.next\n",
    "\n",
    "                \n",
    "            # Move updated node to front of queue    \n",
    "            self.enQueue(node)\n",
    "            return node.value\n",
    "\n",
    "        return -1\n",
    "\n",
    "    # set(key,value)\n",
    "    def set(self, key, value):\n",
    "        \n",
    "        if self.capacity == 0:\n",
    "            print(\"Warning: LRU capacity is 0\")\n",
    "            return\n",
    "        \n",
    "        # Check if key is in map, update or append new node to the front of the queue\n",
    "        if self.hmap.get(key) is not None:\n",
    "            node = self.hmap[key]\n",
    "            node.value = value\n",
    "            node.key = key\n",
    "        else:\n",
    "            # check if LRU is full, remove least used node (tail) from queue\n",
    "            node = LRU_Node(key, value)\n",
    "            if self.num_entries == self.capacity:\n",
    "                self.removeTail()\n",
    "                self.num_entries -= 1\n",
    "            self.hmap[key] = node\n",
    "            self.num_entries += 1\n",
    "            \n",
    "        # add new node to the head of the list\n",
    "        self.enQueue(node)\n",
    "        \n",
    "    # removeTail()\n",
    "    def removeTail(self):\n",
    "\n",
    "        # Check if tail node exists, remove node from queue and hash map\n",
    "        # Update num_entries to reflect number of items in queue\n",
    "        if self.tail:\n",
    "            next_node = self.tail.next\n",
    "            del self.hmap[self.tail.key]\n",
    "            self.tail = next_node\n",
    "\n",
    "    # enQueue(node)\n",
    "    def enQueue(self, node):\n",
    "\n",
    "        # Append node to front of the list, and set tail node to head if new node\n",
    "        # Update num_entries\n",
    "        if self.head:\n",
    "            node_tmp = self.head\n",
    "            self.head = node\n",
    "            node.prev = node_tmp\n",
    "            node_tmp.next = node\n",
    "        else:\n",
    "            self.head = node\n",
    "            self.tail = self.head    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test Case #1: Boilerplate \n",
    "    our_cache = LRU_Cache(5)\n",
    "\n",
    "    our_cache.set(1, 1);\n",
    "    our_cache.set(2, 2);\n",
    "    our_cache.set(3, 3);\n",
    "    our_cache.set(4, 4);\n",
    "\n",
    "    print(our_cache.get(1))  # returns 1\n",
    "    print(our_cache.get(2))  # returns 2\n",
    "    print(our_cache.get(9))  # returns -1 because 9 is not present in the cache\n",
    "\n",
    "    our_cache.set(5, 5) \n",
    "    our_cache.set(6, 6)\n",
    "\n",
    "    print(our_cache.get(3))  # returns -1 because the cache reached it's\n",
    "                             # capacity and 3 was the least recently used entry\n",
    "\n",
    "    # Test Case #2: Warning issued for Zero Capacity LRU\n",
    "    our_cache = LRU_Cache(0)\n",
    "\n",
    "    our_cache.set(1, 1)\n",
    "    # returns warning\n",
    "\n",
    "    print(our_cache.get(1))\n",
    "    # should return -1\n",
    "\n",
    "    # Test Case 3 - updating existing key\n",
    "    our_cache = LRU_Cache(2)\n",
    "\n",
    "    our_cache.set(1, 1)\n",
    "    our_cache.set(2, 2)\n",
    "    our_cache.set(1, 10)\n",
    "\n",
    "    print(our_cache.get(1))\n",
    "    # returns 10\n",
    "\n",
    "    print(our_cache.get(2))\n",
    "    # returns 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: File Recursion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path testdir ===  ['/Users/mukesh/Projects/learning/udacity/dsand/projects/P1/testdir', '/Users/mukesh/Projects/learning/udacity/dsand/projects/P1/testdir/subdir3/subsubdir1', '/Users/mukesh/Projects/learning/udacity/dsand/projects/P1/testdir/subdir5', '/Users/mukesh/Projects/learning/udacity/dsand/projects/P1/testdir/subdir1']\n",
      "\n",
      "Path testdir/subdir3 ===  ['/Users/mukesh/Projects/learning/udacity/dsand/projects/P1/testdir/subdir3/subsubdir1']\n",
      "\n",
      "File(s): *.c not found!\n",
      "Path testdir/subdir4 ===  None\n",
      "\n",
      "Invalid path: ['test.h']\n",
      "Path testdir/test.h ===  None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, fnmatch\n",
    "import re\n",
    "\n",
    "def find_files(suffix, path):\n",
    "    \"\"\"\n",
    "    Find all files beneath path with file name suffix.\n",
    "    Note that a path may contain further subdirectories\n",
    "    and those subdirectories may also contain further subdirectories.\n",
    "    There are no limit to the depth of the subdirectories can be.\n",
    "    Args:\n",
    "      suffix(str): suffix if the file name to be found\n",
    "      path(str): path of the file system\n",
    "    Returns:\n",
    "       a list of paths\n",
    "    \"\"\"\n",
    "\n",
    "    cfiles_dir = []\n",
    "    path = os.getcwd() + \"/\" + path\n",
    "  \n",
    "    extension = re.findall(r'(\\w+\\.\\w+$)', path)\n",
    "    #print(extension)\n",
    "    if len(extension) > 0:\n",
    "        print(\"Invalid path: {}\".format(extension))\n",
    "        return None\n",
    "              \n",
    "    # If path does not exist, return False    \n",
    "    if not os.path.exists(path):\n",
    "        print(\"Path: {} does not exist!\".format(path))\n",
    "        return None \n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file_name in files:\n",
    "            if fnmatch.fnmatch(file_name, suffix):\n",
    "                if root not in cfiles_dir:\n",
    "                    cfiles_dir.append(root)\n",
    "\n",
    "    if len(cfiles_dir) == 0:\n",
    "        print(\"File(s): {} not found!\".format(suffix))\n",
    "        return None\n",
    "    else:   \n",
    "        return cfiles_dir\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    path = \"testdir\"\n",
    "    print(f\"Path {path} === \", find_files(\"*.c\", path), end='\\n\\n')\n",
    "\n",
    "    path = \"testdir/subdir3\"\n",
    "    print(f\"Path {path} === \", find_files(\"*.c\", path), end='\\n\\n')\n",
    "\n",
    "    path = \"testdir/subdir4\"\n",
    "    print(f\"Path {path} === \", find_files(\"*.c\", path), end='\\n\\n')\n",
    "\n",
    "    path = \"testdir/test.h\"\n",
    "    print(f\"Path {path} === \", find_files(\"*.c\", path), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Huffman Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the data is: 69\n",
      "\n",
      "The content of the data is: The bird is the word\n",
      "\n",
      "The size of the encoded data is: 36\n",
      "\n",
      "The content of the encoded data is: 1000111111100100001101110000101110110110100011111111001101010011100001\n",
      "\n",
      "The size of the decoded data is: 69\n",
      "\n",
      "The content of the encoded data is: The bird is the word\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import heapq as h\n",
    "import sys\n",
    "\n",
    "debug = 0\n",
    "class HeapNode:\n",
    "    def __init__(self, char, frequency):\n",
    "        self.char = char\n",
    "        self.frequency = frequency\n",
    "        self.right = None\n",
    "        self.left = None\n",
    "        \n",
    "    def __lt__(self, other):\n",
    "        return self.frequency < other.frequency\n",
    "        \n",
    "    def __str__(self, level=0):\n",
    "        ret = \"\\t\"*level+repr(self.char)+\"\\n\"\n",
    "        return ret\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.frequency\n",
    "    \n",
    "        \n",
    "class HuffmanCode:\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        self.huff_tree = []\n",
    "        self.codes = dict()\n",
    "        self.decodes = dict()\n",
    "        \n",
    "    \n",
    "    def createFrequencyDict(self):\n",
    "\n",
    "        # Create Hash Counter for character frequency, handles spaces\n",
    "        freq_dict = dict()\n",
    "        for char in self.text:\n",
    "            if char not in freq_dict.keys():\n",
    "                freq_dict[char] = 1\n",
    "            else:\n",
    "                freq_dict[char] += 1\n",
    "                    \n",
    "        return freq_dict\n",
    "\n",
    "    def createTree(self, freq_dict):\n",
    "\n",
    "        for char in freq_dict.keys():\n",
    "            char_node = HeapNode(char, freq_dict[char])\n",
    "            h.heappush(self.huff_tree, char_node)\n",
    "\n",
    "        # merging nodes in Heap    \n",
    "        while len(self.huff_tree) > 1:\n",
    "            node1 = h.heappop(self.huff_tree)\n",
    "            node2 = h.heappop(self.huff_tree)\n",
    "\n",
    "            # Creating new node with \"empty\" character value, but combining frequency weights\n",
    "            # Set pointer to child nodes, left child < right child\n",
    "            merged_node = HeapNode(None, node1.frequency + node2.frequency)\n",
    "            merged_node.left = node1\n",
    "            merged_node.right = node2\n",
    "\n",
    "            # Push merged_node back into the heap\n",
    "            h.heappush(self.huff_tree, merged_node)\n",
    "\n",
    "\n",
    "    def createCodeDict_helper(self, root, current_code):\n",
    "        if root == None:\n",
    "            return\n",
    "        \n",
    "        if root.char != None:\n",
    "            if len(current_code) > 0:\n",
    "                self.codes[root.char] = current_code\n",
    "                self.decodes[current_code] = root.char\n",
    "            else:\n",
    "                current_code = '0'\n",
    "                self.codes[root.char] = current_code\n",
    "                self.decodes[current_code] = root.char\n",
    "            return\n",
    "        \n",
    "        self.createCodeDict_helper(root.left, current_code + \"0\")\n",
    "        self.createCodeDict_helper(root.right, current_code + \"1\")\n",
    "        \n",
    "        \n",
    "    def createCodeDict(self):\n",
    "        root = h.heappop(self.huff_tree)\n",
    "        current_code = \"\"\n",
    "        self.createCodeDict_helper(root, current_code)\n",
    "\n",
    "\n",
    "    def encodeText(self, text):\n",
    "        encoded_text = \"\"\n",
    "\n",
    "        for character in text:\n",
    "            encoded_text += self.codes[character]\n",
    "    \n",
    "        return encoded_text\n",
    "\n",
    "\n",
    "    def decodeText(self, encoded_text):\n",
    "        current_code = \"\"\n",
    "        decoded_text = \"\"\n",
    "\n",
    "        if encoded_text != -1:\n",
    "            for bit in encoded_text:\n",
    "                current_code += bit\n",
    "                if(current_code in self.decodes):\n",
    "                    character = self.decodes[current_code]\n",
    "                    decoded_text += character\n",
    "                    current_code = \"\"\n",
    "        else:\n",
    "            decoded_text = -1\n",
    "            \n",
    "        return decoded_text\n",
    "\n",
    "\n",
    "\n",
    "def huffman_encoding(data):\n",
    "    huff_code = -1\n",
    "    hcode = None\n",
    "    \n",
    "    if len(data) > 0:\n",
    "        hcode = HuffmanCode(data)\n",
    "        frequency_dict = hcode.createFrequencyDict()\n",
    "        hcode.createTree(frequency_dict)\n",
    "        hcode.createCodeDict()\n",
    "        huff_code = hcode.encodeText(data)\n",
    "    \n",
    "    else:\n",
    "        print(\"Input data is empty string, returning {}!\".format(huff_code))\n",
    "    \n",
    "    return huff_code, hcode\n",
    "\n",
    "def huffman_decoding(data,tree):\n",
    "    text = -1\n",
    "\n",
    "    if data != -1:\n",
    "        text = tree.decodeText(data)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    codes = {}\n",
    "\n",
    "    a_great_sentence = \"The bird is the word\"\n",
    "\n",
    "    print (\"The size of the data is: {}\\n\".format(sys.getsizeof(a_great_sentence)))\n",
    "    print (\"The content of the data is: {}\\n\".format(a_great_sentence))\n",
    "\n",
    "    encoded_data, tree = huffman_encoding(a_great_sentence)\n",
    "\n",
    "    print (\"The size of the encoded data is: {}\\n\".format(sys.getsizeof(int(encoded_data, base=2))))\n",
    "    print (\"The content of the encoded data is: {}\\n\".format(encoded_data))\n",
    "\n",
    "    decoded_data = huffman_decoding(encoded_data, tree)\n",
    "\n",
    "    print (\"The size of the decoded data is: {}\\n\".format(sys.getsizeof(decoded_data)))\n",
    "    print (\"The content of the encoded data is: {}\\n\".format(decoded_data))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Active Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Windows Active Directory, a group can consist of user(s) and group(s) themselves. We can construct this hierarchy as such. Where User is represented by str representing their ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Group(object):\n",
    "    def __init__(self, _name):\n",
    "        self.name = _name\n",
    "        self.groups = []      # list of class Groups\n",
    "        self.users = []       # list of string user\n",
    "\n",
    "    def add_group(self, group):\n",
    "        if debug: print(\"[[add_group]]: {}\".format(group))\n",
    "        self.groups.append(group)\n",
    "\n",
    "    def add_user(self,user):\n",
    "        if debug: print(\"[[add_user]]: {}\".format(user))\n",
    "        self.users.append(user)\n",
    "\n",
    "    def get_groups(self):\n",
    "        return self.groups\n",
    "\n",
    "    def get_users(self):\n",
    "        return self.users\n",
    "\n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "\n",
    "    \n",
    "def is_user_in_group(user, group, grp_queue = None):\n",
    "\n",
    "    group_queue = []\n",
    "\n",
    "    # Match user to group's name\n",
    "    if user == group.get_name():\n",
    "        # print(\"user matches group name\")\n",
    "        return True\n",
    "    \n",
    "    # Match user to get_users\n",
    "    elif user in group.get_users():\n",
    "        # print(\"user is in group's user list\")\n",
    "        return True\n",
    "    \n",
    "    # if Group's group list not empty, recurse \n",
    "    if len(group.get_groups()) == 0:\n",
    "        # print(\"group's group list is empty, return False\")\n",
    "        return False\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        # print(\"group.name = {}\".format(group.get_name()))\n",
    "        # print(\"Descend into Group's group at a time, group_list: {}\".format(group.get_groups()))\n",
    "        if grp_queue is None:\n",
    "            grp_queue = group.get_groups()\n",
    "            return is_user_in_group(user, group, grp_queue)\n",
    "\n",
    "        else:\n",
    "            grp_queue += group.get_groups()  \n",
    "            return is_user_in_group(user, grp_queue.pop(0), grp_queue)\n",
    "\n",
    "if __name__ == \"__main__\":                  \n",
    "    parent = Group(\"parent\")\n",
    "    child = Group(\"child\")\n",
    "    sub_child = Group(\"subchild\")\n",
    "\n",
    "    sub_child_user = \"sub_child_user\"\n",
    "    sub_child.add_user(sub_child_user)\n",
    "\n",
    "    child.add_group(sub_child)\n",
    "    parent.add_group(child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Blockchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Blockchain is a sequential chain of records, similar to a linked list. Each block contains some information and how it is connected related to the other blocks in the chain. Each block contains a cryptographic hash of the previous block, a timestamp, and transaction data. For our blockchain we will be using a SHA-256 hash, the Greenwich Mean Time when the block was created, and text strings as the data.\n",
    "\n",
    "Use your knowledge of linked lists and hashing to create a blockchain implementation.\n",
    "\n",
    "\n",
    "We can break the blockchain down into three main parts.\n",
    "\n",
    "First is the information hash:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing: timestamp, data, previous_hash, hash_code\n",
      "0612_1950\n",
      "N1\n",
      "None\n",
      "b79f477f6d435116155b1121455748240bb5e7c81f7043519980df21a8167ca1\n",
      "***\n",
      "Printing: timestamp, data, previous_hash, hash_code\n",
      "0612_2042\n",
      "N2\n",
      "b1\n",
      "2a5f06422d35ac8977cbf311a3178de243428e2c1ca836ed16477cac024360ec\n",
      "***\n",
      "Printing: timestamp, data, previous_hash, hash_code\n",
      "0623_2331\n",
      "N3\n",
      "b2\n",
      "2da09e1fac71f1257e0efcb158f2d71e7d11ccb7a7db83461ce7f4cade83e770\n",
      "***\n",
      "Printing: timestamp, data, previous_hash, hash_code\n",
      "\n",
      "\n",
      "\n",
      "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "class Block:\n",
    "\n",
    "    def __init__(self, timestamp, data, previous_hash):\n",
    "        self.timestamp = timestamp\n",
    "        self.data = data\n",
    "        self.prev = None\n",
    "        self.previous_hash = previous_hash\n",
    "        self.hash = self.calc_hash(self.data)\n",
    "\n",
    "    def calc_hash(self, string):\n",
    "        sha = hashlib.sha256()\n",
    "\n",
    "        self.string = string\n",
    "        hash_str = self.string.encode('utf-8')\n",
    "        sha.update(hash_str)\n",
    "\n",
    "        return sha.hexdigest()\n",
    "  \n",
    "\n",
    "    def _print(self):\n",
    "        print(\"Printing: timestamp, data, previous_hash, hash_code\")\n",
    "        print(self.timestamp)\n",
    "        print(self.data)\n",
    "        print(self.previous_hash)\n",
    "        print(self.hash)\n",
    "\n",
    "class BlockChain:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "        self.tail = None     \n",
    "            \n",
    "          \n",
    "    def append(self, timestamp, data, previous_hash):\n",
    "            \n",
    "        if self.head is None:\n",
    "            #print(\"head is none, instantiate Block()\")\n",
    "            self.head = Block(timestamp, data, previous_hash)\n",
    "            #self.head._print()\n",
    "            self.tail = self.head\n",
    "        else:\n",
    "            #print(\"head exists, instantiate new node to  Block()\")\n",
    "            new_node = Block(timestamp, data, previous_hash)\n",
    "            #new_node._print()\n",
    "            self.head.prev = new_node\n",
    "            #self.tail = self.head\n",
    "            #print(\"new_node: {}\".format(new_node))\n",
    "            #print(\"self.head.prev: {}\".format(self.head.prev))\n",
    "            #print(\"self.tail: {}\".format(self.tail))\n",
    "            #print(\"before update, self.head: {}\".format(self.head))\n",
    "            self.head = new_node\n",
    "            #print(\"after update, self.head: {}\".format(self.head))\n",
    "            \n",
    "\n",
    "    def print(self, index=0):\n",
    "        #print(\"[[print]]\")\n",
    "        if index == 0: \n",
    "            if self.tail is not None:\n",
    "                self.tail._print()\n",
    "        else:\n",
    "         #   print(\"[[Passed arg]] index: {}\".format(index))\n",
    "            node = self.tail\n",
    "            idx = 0\n",
    "            while node != None:\n",
    "                #print(\"idx: {}\".format(idx))\n",
    "                if idx == index:\n",
    "                    node._print()\n",
    "                    return\n",
    "                node = node.prev\n",
    "                idx +=1\n",
    "                #print(\"increment idx: {}\".format(idx))\n",
    "                \n",
    "if __name__ == \"__main__\":                \n",
    "    # Test Case 1                \n",
    "    b1 = BlockChain()\n",
    "    b1.append('0612_1950', \"N1\", None)\n",
    "    b1.print()\n",
    "\n",
    "    # Test Case 2\n",
    "    print(\"***\")\n",
    "    b1.append('0612_2042', \"N2\", \"b1\")\n",
    "    b1.print(1)\n",
    "\n",
    "    # Test Case 3\n",
    "    print(\"***\")\n",
    "    b1.append('0623_2331', \"N3\", \"b2\")\n",
    "    b1.print(2)\n",
    "\n",
    "    # Test Case 4: printing empty block node\n",
    "    print(\"***\")\n",
    "    b1.append('', \"\", \"\")\n",
    "    b1.print(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6: Union and Intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 -> 65 -> 2 -> 35 -> 3 -> 4 -> 6 -> 1 -> 9 -> 11 -> 21 -> \n",
      "4 -> 21 -> 6 -> \n",
      "65 -> 2 -> 35 -> 3 -> 4 -> 6 -> 1 -> 7 -> 8 -> 9 -> 11 -> 21 -> 23 -> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Node:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.next = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.value)\n",
    "\n",
    "class LinkedList:\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "        self.size = 0\n",
    "        \n",
    "    def __str__(self):\n",
    "        cur_head = self.head\n",
    "        out_string = \"\"\n",
    "        while cur_head:\n",
    "            out_string += str(cur_head.value) + \" -> \"\n",
    "            cur_head = cur_head.next\n",
    "\n",
    "        return out_string\n",
    "\n",
    "    def append(self, value):\n",
    "        if self.head is None:\n",
    "            self.head = Node(value)\n",
    "            return\n",
    "\n",
    "        node = self.head\n",
    "        while node.next:\n",
    "            node = node.next\n",
    "\n",
    "        node.next = Node(value)\n",
    "        self.size += 1\n",
    "        \n",
    "    def size(self):\n",
    "        size = 0\n",
    "        node = self.head\n",
    "        while node:\n",
    "            size += 1\n",
    "            node = node.next\n",
    "\n",
    "        return size\n",
    "\n",
    "\n",
    "def convertLList_to_PySet(llist):\n",
    "    pylist = []\n",
    "\n",
    "    node = llist.head\n",
    "    while node:\n",
    "        pylist.append(node.value)\n",
    "        node = node.next\n",
    "\n",
    "    pyset = set(pylist)\n",
    "    return pyset\n",
    "\n",
    "    \n",
    "def union(llist_1, llist_2):\n",
    "\n",
    "    l1 = convertLList_to_PySet(llist_1)\n",
    "    l2 = convertLList_to_PySet(llist_2)\n",
    "\n",
    "    union = l1 | l2\n",
    "\n",
    "    llist = LinkedList()\n",
    "\n",
    "    for value in union:\n",
    "        llist.append(value)\n",
    "        \n",
    "    return llist\n",
    "\n",
    "\n",
    "def intersection(llist_1, llist_2):\n",
    "\n",
    "    l1 = convertLList_to_PySet(llist_1)\n",
    "    l2 = convertLList_to_PySet(llist_2)\n",
    "\n",
    "    intersection = l1 & l2\n",
    "\n",
    "    llist = LinkedList()\n",
    "    for value in intersection:\n",
    "        llist.append(value)\n",
    "\n",
    "    return llist\n",
    "\n",
    "def printList(llist):\n",
    "    \n",
    "    node = llist.head\n",
    "    while node:\n",
    "        print(node.value)\n",
    "        node = node.next\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    linked_list_1 = LinkedList()\n",
    "    linked_list_2 = LinkedList()\n",
    "\n",
    "    element_1 = [3,2,4,35,6,65,6,4,3,21]\n",
    "    element_2 = [6,32,4,9,6,1,11,21,1]\n",
    "\n",
    "    for i in element_1:\n",
    "        linked_list_1.append(i)\n",
    "\n",
    "    for i in element_2:\n",
    "        linked_list_2.append(i)\n",
    "\n",
    "    print (union(linked_list_1,linked_list_2))\n",
    "    print (intersection(linked_list_1,linked_list_2))\n",
    "\n",
    "    # Test case 2\n",
    "\n",
    "    linked_list_3 = LinkedList()\n",
    "    linked_list_4 = LinkedList()\n",
    "\n",
    "    element_1 = [3,2,4,35,6,65,6,4,3,23]\n",
    "    element_2 = [1,7,8,9,11,21,1]\n",
    "\n",
    "    for i in element_1:\n",
    "        linked_list_3.append(i)\n",
    "\n",
    "    for i in element_2:\n",
    "        linked_list_4.append(i)\n",
    "\n",
    "    print (union(linked_list_3,linked_list_4))\n",
    "    print (intersection(linked_list_3,linked_list_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
